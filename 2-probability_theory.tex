\chapter{Probability in Theory}

Logic provides a framework for how we can describe systems with certainty,
and the tools of probability theory allow us to assign uncertainty to logical
statements and implications.  We begin this chapter with an introduction of
measures, which allow us to assign values to logical statements, and then
probability measures, which limit those value to probabilities.  We end with
a discussion of conditional probability distributions over implications.

Unfortunately, the abstraction of probability theory means that we cannot rely 
on explicit examples, and subsequent visualizations, to support the definitions 
and manipulations introduced in this chapter.  That context will have to wait
until the next chapter where we discus how to implement probability theory
in practice.

\section{Measures}

The first step towards assigning uncertainty to logical statements is to
assign \emph{any} positive value.  A \emph{measure} accomplishes this
by assigning a positive value to all events in the chosen event space,
%
\begin{equation*}
\mathbb{M} : \mathcal{E} \! \left( \Theta \right) \rightarrow \mathbb{R}^{+}.
\end{equation*}
%
The term measure often serves multiple uses depending on context.
It can, for example, refer to the object which assigns values to each
event or the value assigned to the event, as in ``the measure of the 
event $E$ is $\mathbb{M} \! \left[ E \right]$''.

Because a measure assigns values to only events, we need both a
sample space and an event space in order to define measure.  In
other words, we can define measures only on measurable spaces.  
This is the ultimate motivation for this term, as measurable spaces 
are most often introduces only as a precursor to measures themselves.

Provided that the measure of each event is finite, 
%
\begin{equation*}
\mathbb{M} \! \left[ E \right] < \infty, \, \forall E \in \EV{\Theta},
\end{equation*}
%
the assignment of measures is naturally compatible with the manipulations 
of logical statements.  For example, the measure of conjunctions and
disjunction are related as
%
\begin{equation*}
\mathbb{M} \! \left[ E_{1} \cup E_{2} \right]
= 
\mathbb{M} \! \left[ E_{1} \right] + \PP \! \left[ E_{2} \right] 
- \mathbb{M} \! \left[ E_{1} \cap E_{2} \right],
\end{equation*}
%
and negations satisfy,
%
\begin{equation*}
\mathbb{M} \! \left[ E \right] 
= 
\mathbb{M} \! \left[ \Theta \right] - \PP \! \left[ E^{c} \right]
=
1 - \mathbb{M} \! \left[ E^{c} \right].
\end{equation*}
%
By definition all events have finite measure, and all of these results
hold, provided that the trivial event has finite measure, 
$\mathbb{M} \! \left[ \Theta \right] < \infty$.

Measures can also be used to integrate functions over the sample
space in a procedure known as \emph{Lebesgue integration},
%
\begin{equation*}
\mathcal{I}_{\mathbb{M}} : 
\mathcal{F} \! \left( \Theta \right) \rightarrow \mathbb{R},
\end{equation*}
%
where $\mathcal{F} \! \left( \Theta \right)$ is the collection of well-behaved 
functions $f : \Theta \rightarrow \mathbb{R}$.  In fact, we can also consider 
measure assignments themselves as expectations,
%
\begin{equation*}
\mathbb{M} \! \left[ E \right] 
= 
\mathcal{I}_{\mathbb{M}} \! \left[ \mathbb{I}_{E} \right],
\end{equation*}
%
where the \emph{indicator function} of the event $E$, $\mathbb{I}_{E}$,
is defined as
%
\begin{equation*}
\mathbb{I}_{E} \! \left( \theta \right)
= 
\left\{
\begin{array}{rr}
0, & \theta \notin E \\
1, & \theta \in E
\end{array}
\right. .
\end{equation*}
%
In particular, the Lebesgue integral of every well-behaved function
completely specifies every measure.

In some cases Lebesgue integration can also be used to emulate 
one measure other.  Consider two measures $\mathbb{M}_{1}$
and $\mathbb{M}_{2}$ where $\mathbb{M}_{2} \! \left[ E \right] = 0$
whenever $\mathbb{M}_{1} = 0$.  We say that any measure 
$\mathbb{M}_{2}$ satisfying this property is \emph{absolutely continuous} 
with respect to $\mathbb{M}_{1}$.  

When $\mathbb{M}_{2}$ is absolutely continuous with respect to
$\mathbb{M}_{1}$, the Lebesgue integral of any well-behaved
function, $f$, can be recovered as a Lebesgue integral with 
respect to $\mathbb{M}_{1}$,
%
\begin{equation*}
\mathcal{I}_{\mathbb{M}_{2}} \! \left[ f \right]
=
\mathcal{I}_{\mathbb{M}_{1}} \! \left[ \nu \cdot f \right],
\end{equation*}
%
where $\nu \in \mathcal{F} \! \left( \Theta \right)$ is a bounded function
known as the \emph{Radon-Nikodym derivative} of $\mathbb{M}_{2}$ 
with respect to $\mathbb{M}_{1}$.  

The Radon-Nikodym derivative is often written as
%
\begin{equation*}
\nu = \frac{ \mathrm{d} \mathbb{M}_{2} }{ \mathrm{d} \mathbb{M}_{1} }
\end{equation*}
%
to make the relevant measures more explicit.  Moreover, it typical to
abuse notation a bit and write
%
\begin{equation*}
\mathbb{M}_{2} = 
\frac{ \mathrm{d} \mathbb{M}_{2} }{ \mathrm{d} \mathbb{M}_{1} } 
\mathbb{M}_{1}
\end{equation*}
%
as shorthand for the Lebesgue integral relationship above.

\section{Probability Distributions}

When we are uncertain about our target system then we cannot
guarantee that any particular logical statement in true.  In order to
quantify uncertainty about our descriptions we assign to each event 
a \emph{probability} that quantifies how plausible it is be true.  
Probabilities themselves are bounded between 0, indicating that an 
event is absolutely false, and 1, indicating that an event is absolutely
true.

A \emph{probability distribution} is a measure restricting to assigning
probabilities to each event,
%
\begin{equation*}
\PP : \mathcal{E} \! \left( \Theta \right) \rightarrow \left[0, 1 \right],
\end{equation*}
%
such that the probability of the null event is zero, 
$\PP \! \left[ \emptyset \right] = 0$, and the probability of the trivial
event is one, $\PP \! \left[ \Theta \right] = 1$.  These latter two conditions 
are an immediate consequence of our initial assumption that our descriptions
can be represented by the sample space.  When using a probability distribution 
to quantify our uncertainty about a system expressed with the sample
space $\Theta$, we often write $\theta \sim \PP$ which is read as, 
``$\theta$ is distributed according to the probability distribution $\PP$''
but should really read ``Logical statements about $\Theta$ are assigned 
probabilities according to the probability distribution $\PP$''.

The assignment of probabilities to conjunctions, disjunctions, and 
negations become the familiar rules of probability.  For example, the
the probability of conjunctions becomes the sum rule,
%
\begin{equation*}
\PP \! \left[ E_{1} \cup E_{2} \right]
= 
\PP \! \left[ E_{1} \right] + \PP \! \left[ E_{2} \right] 
- \PP \! \left[ E_{1} \cap E_{2} \right],
\end{equation*}
%
and the probability of negation becomes the rule of total probability,
%
\begin{equation*}
\PP \! \left[ E \right] 
= 
\PP \! \left[ \Theta \right] - \PP \! \left[ E^{c} \right]
=
1 - \PP \! \left[ E^{c} \right].
\end{equation*}

Lebesgue integrals with respect to probability measures are better
known as \emph{expectation values},
%
\begin{equation*}
\EE_{\PP} : \mathcal{F} \! \left( \Theta \right) \rightarrow \mathbb{R},
\end{equation*}
%
Common expectations include means, variances, and higher-order moments.

The most important consequence of these definitions is that \emph{all of 
probability theory reduces to computing expectations}.  Any other operation 
that you may have encountered in probability theory can only ever be an
intermediate step in computing a final expectation.  In particular, many of 
the more non-intuitive aspects of probability theory can avoided by carefully
framing everything as an expectation -- don't try to intuit solutions, calculate 
them!

\section{Conditional Probability Distributions}

\emph{Conditional probability distributions} allow us to quantify uncertainty
about implications.  While implications assign an event to each value of the 
conditioning space, $\Phi$, a conditional probability distribution assigns a 
probability distribution to each value in the conditioning space,
%
\begin{align*}
\PP_{\Theta \mid \Phi} 
&: \EV{\Theta} \times \Phi \rightarrow \left[0, 1 \right] \\
&\quad \left( E_{\Theta}, \phi \right) \;\; \mapsto 
\PP_{\Theta \mid \Phi} \! \left[ E_{\Theta} \mid \phi \right].
\end{align*}
%
In other words, for any value of $\phi \in \Phi$ the conditional probability
distribution defines a probability distribution on $\Theta$, and for any
event in $\Theta$ the conditional probability distribution defines a 
function from $\Phi$ to probabilities.  

\subsection{Joint Distributions and Marginal Distributions}

As with implications, conditional probability distributions can be used
to construct probability distributions on larger spaces.  In particular,
by combining a conditional probability distribution with a probability distribution 
on the conditioning space, $\Phi$, we can construct a probability distribution 
on the joint sample space, $\Theta \times \Phi$.  

This \emph{joint distribution} is defined implicitly by its probability assignments 
or expectation values.  For example, the probability of any joint event, 
$E_{\Theta} \times E_{\Phi}$, is given by first using the conditional probability 
distribution to assign a probability 
to $E_{\Theta}$, $\PP_{\Theta|\Phi} \! \left[ E_{\Theta} \mid \phi \right]$, and 
then taking the expectation of this assignment over the distribution on $\Phi$,
%
\begin{equation*}
\PP_{\Theta \times \Phi} \! \left[ E_{\Theta} \times E_{\Phi} \right]
=
\mathbb{E}_{\PP_{\Phi}} \! \left[  
\PP_{\Theta|\Phi} \! \left[ E_{\Theta} \mid \phi \right] 
\cdot \mathbb{I}_{E_{\Phi}} \! \left( \phi \right)
\right],
\end{equation*}
%
where the indicator function, $\mathbb{I}_{E_{\Phi}}$, ensures that we 
take the expectation only over the event in $\Phi$.  Similarly, joint 
expectations are defined iteratively as
%
\begin{equation*}
\EE_{\PP_{\Theta \times \Phi}} \! \left[ g \! \left( \theta, \phi \right) \right]
=
\mathbb{E}_{\PP_{\Phi}} \! \left[  
\EE_{\PP_{\Theta|\Phi}} \! \Big[ 
g \! \left( \theta, \phi \right) \mid \phi 
\Big]
\right].
\end{equation*}

If we consider only the trivial event on the conditioning space $E_{\Phi} 
= \Phi$, then this construction also defines a  \emph{marginal distribution} 
on $\Theta$ by
%
\begin{align*}
\PP_{\Theta} \! \left[ E_{\Theta} \right]
&\equiv
\PP_{\Theta \times \Phi} \! \left[ E_{\Theta} \times \Phi \right] \\
&=
\mathbb{E}_{\PP_{\Phi}} \! \left[  
\PP_{\Theta|\Phi} \! \left[ E_{\Theta} \mid \phi \right]
\right],
\end{align*}
or
%
\begin{align*}
\EE_{\PP_{\Theta}} \! \left[ f \! \left( \theta \right) \right]
&\equiv
\EE_{\PP_{\Theta \times \Phi}} \! \left[ f \! \left( \theta \right) \right] \\
&=
\mathbb{E}_{\PP_{\Phi}} \! \left[  
\EE_{\PP_{\Theta|\Phi}} \! \Big[ 
f \! \left( \theta \right) \mid \phi 
\Big]
\right].
\end{align*}
%
This marginalization process allows us to collapse a joint probability 
distribution onto any of the component spaces, explicitly incorporating 
any interactions between the components.

\subsection{Generative Modeling}

Just as we can build logical statements sequentially from simpler
implications, we can build distributions over high-dimensional product
spaces sequentially from conditional probability distributions.  Mirroring the
procedure for implications, we start with a probability distribution on one 
low-dimensional component of the target space and then build up a joint 
distribution by adding conditional probability distributions for each new 
component,
%
\begin{align*}
& \PP_{\Theta_{1}} \\
& \PP_{\Theta_{2} \mid \Theta_{1}} \\
& \PP_{\Theta_{3} \mid \Theta_{2}, \Theta_{1}} \\
& \cdots \\
& \PP_{\Theta_{N} \mid \Theta_{N - 1}, \ldots, \Theta_{2}, \Theta_{1}}.
\end{align*}

As with implications, these conditional probability distributions are often 
motivated by the natural structure of our target system.  In particular, if we 
think about deterministic processes as degenerate conditional probability 
distributions that assign all probability to a single event for each conditioning 
value,
%
\begin{equation*}
\PP_{\Theta \mid \Phi} \! \left[ E_{\Theta} \mid \phi \right]
= 
\left\{
\begin{array}{rr}
0, & E_{\Theta} \ne \hat{E} \! \left( \phi \right) \\
1, & E_{\Theta} = \hat{E} \! \left( \phi \right)
\end{array}
\right.,
\end{equation*}
%
then these conditional probability distributions can seamlessly incorporate
both stochastic and deterministic, causal relationships.  This iterative process 
of building a joint probability distribution from conditional probability distributions 
is the key building block of \emph{generative modeling}.

\subsection{Bayes' Theorem}

While we can decompose a joint probability distribution into a conditional
probability distribution and a marginal distribution, there is not unique
decomposition.  For example, a joint probability distribution on 
$\Theta \times \Phi$ can be decomposed into $\PP_{\Theta \mid \Phi}$ and
$\PP_{\Phi}$ or $\PP_{\Phi \mid \Theta}$ and $\PP_{\Theta}$.

The equivalence of these two decompositions immediately implies
\emph{Bayes' Theorem} which allows us to define any one of these
distributions from the other three using Radon-Nikodym derivatives. 
If $\PP_{\Theta \mid \Phi}$ and $\PP_{\Theta}$ are absolutely continuous
with respect to each other then we have,
%
\begin{align*}
\PP_{\Theta \mid \Phi} &= 
\frac{ \mathrm{d} \PP_{\Phi \mid \Theta} }{ \mathrm{d} \PP_{\Phi} }
\PP_{ \Theta}
\\
\PP_{\Theta} &= 
\frac{ \mathrm{d} \PP_{\Phi} }{ \mathrm{d} \PP_{\Phi \mid \Theta} }
\PP_{ \Theta \mid \Phi }
\end{align*}
%
Similarly, if $\PP_{\Phi \mid \Theta}$ and $\PP_{\Phi}$ are absolutely 
continuous with respect to each other then we have the two additional
equalities
%
\begin{align*}
\PP_{\Phi \mid \Theta} &= 
\frac{ \mathrm{d} \PP_{\Theta \mid \Phi} }{ \mathrm{d} \PP_{\Theta} }
\PP_{\Phi}
\\
\PP_{\Theta \mid \Phi} &= 
\frac{ \mathrm{d} \PP_{\Theta} }{ \mathrm{d} \PP_{\Theta \mid \Phi} }
\PP_{ }.
\end{align*}

Although an immediate consequence of our definitions, Bayes' Theorem
has extraordinarily important consequences in the application of
probability theory.  These equalities allow us to invert any implicative 
structure -- if we have a probabilistic model for how logical statements
in $\Phi$ affect logical statements in $\Theta$, then Bayes' Theorem
identifies how logical statements in $\Theta$ affect logical statements
in $\Phi$.

\section{The Invariance of Probability Distributions}

Like events, probability distributions can be defined with respect to many different 
sample spaces.  If $s : \Theta \rightarrow \Omega$ is a measurable map and 
$\PP_{\Theta}$ is a probability distribution defined over events in $\Theta$, then 
we can define an equivalent \emph{pushforward} probability distribution over 
events in $\Omega$ by assigning probabilities as
%
\begin{equation*}
\PP_{\Omega} \! \left[ E_{\Omega} \right]
\equiv
\PP_{\Theta} \! \left[ s^{-1} \! \left( E_{\Omega} \right) \right].
\end{equation*}
%
As with measurable spaces, the measurable in measurable maps refers to
their application to pushing measures forward along the map.

Furthermore, if the map is doubly-measurable then this whole process can be 
inverted: if $\PP_{\Omega}$ is a probability distribution defined over events in 
$\Omega$ then we can define an equivalent pushforward probability distribution 
over events in $\Theta$ by assigning probabilities as
%
\begin{equation*}
\PP_{\Theta} \! \left[ E_{\Theta} \right]
\equiv
\PP_{\Omega} \! \left[ s \! \left( E_{\Theta} \right) \right].
\end{equation*}

These probability distributions are invariant when we move between equivalent 
sample spaces, and hence are fundamental to the underlying abstract system 
and not any particular representation of that system.  Different but equivalent 
sample spaces are just different ways to describe the same system, with events 
quantifying the same, invariant information and probability distributions quantifying
the same, invariant uncertainty.
